{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "82h7cjYWCTM8"
      },
      "outputs": [],
      "source": [
        "#Libraries includig keras, numpy and matplot etc\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "#from keras.optimizers import SGD\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9mN2GpdowB2",
        "outputId": "2336dc1b-c59c-459f-9237-8cfe08322b23"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the images you can get them through the link in report\n",
        "data = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Project2/Aug\",\n",
        "    labels='inferred',label_mode='binary',image_size=(128,128),\n",
        "    batch_size=1,shuffle=True,seed=5\n",
        "    )\n"
      ],
      "metadata": {
        "id": "6_xPNOq0B1ON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f30405-9dc6-4c27-a505-14aca2797b32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 69 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = data.class_names\n"
      ],
      "metadata": {
        "id": "wC35ia2BpfUE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Inputs and Labels\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in data.as_numpy_iterator():\n",
        "  dataX.append(i[0])\n",
        "  dataY.append(i[1])\n",
        "dataX = np.array(dataX)\n",
        "dataY = np.array(dataY)\n"
      ],
      "metadata": {
        "id": "C5Fv2-S8tGhJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset and return train values\n",
        "def load_dataset(): \n",
        "  trainX, trainY= dataX,dataY\n",
        "  # reshape dataset to have a single channel\n",
        "  trainX = trainX.reshape((trainX.shape[0],128,128,3))\n",
        "\n",
        "  return trainX, trainY\n"
      ],
      "metadata": {
        "id": "CTa1ah1b3spO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_pixels(train):\n",
        "  # convert from integers to floats\n",
        "  train_norm = train.astype('float32')\n",
        "  # normalize to range 0-1\n",
        "  train_norm = train_norm / 255.0\n",
        "  # return normalized images\n",
        "  return train_norm"
      ],
      "metadata": {
        "id": "RnONMKzYU4_5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining/Making a model with multiple convultional and Maxpooling layers then flatten it to use in our main model\n",
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(128,128,3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # compile model\n",
        "  model.compile(optimizer=Adam(lr=0.001), loss=binary_crossentropy, metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fHSoxgUYokR5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate a model using k-fold cross-validation\n",
        "#It all find F1,recalls and other features for each fold\n",
        "def train_and_evaluate_model(dataX, dataY, n_folds=3):\n",
        "  train_accuracies = []\n",
        "  val_accuracies = []\n",
        "  f1_scores = []\n",
        "  precisions = []\n",
        "  recalls = []\n",
        "  roc_aucs = []\n",
        "  scores, histories = list(), list()\n",
        "  # prepare cross validation\n",
        "  kfold = KFold(n_folds, shuffle=True, random_state=4)\n",
        "  # enumerate splits\n",
        "\n",
        "  for train_ix, test_ix in kfold.split(dataX):\n",
        "    # define model\n",
        "    model = define_model()\n",
        "    # select rows for train and test\n",
        "    trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "    # fit model\n",
        "    history = model.fit(trainX, trainY, epochs=10, batch_size=10, validation_data=(testX, testY), verbose=1)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=1)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "    # stores scores\n",
        "    scores.append(acc)\n",
        "\n",
        "        # Fit the model on the current training data\n",
        "   \n",
        "        # Get the training and validation accuracy\n",
        "    train_acc = model.evaluate(trainX, trainY, verbose=0)[1]\n",
        "    val_acc = model.evaluate(testX, testY, verbose=0)[1]\n",
        "        # Get the predictions on the validation data\n",
        "    val_preds = model.predict(testX)\n",
        "    val_preds = np.round(val_preds)\n",
        "    testY = testY.reshape(-1)\n",
        "    \n",
        "\n",
        "        # Get the F1 score, precision, recall, and ROC AUC\n",
        "    f1 = f1_score(testY, val_preds)\n",
        "    precision = precision_score(testY, val_preds)\n",
        "    recall = recall_score(testY, val_preds)\n",
        "    roc_auc = roc_auc_score(testY, val_preds)\n",
        "\n",
        "\n",
        "    print('f1 score: ',f1)\n",
        "    print('Precision:', precision)\n",
        "    print('Recall:', recall)\n",
        "    print('AUC: ',roc_auc)\n",
        "\n",
        "\n",
        "        # Append the metrics to the lists\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(val_acc)\n",
        "    f1_scores.append(f1)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    roc_aucs.append(roc_auc)\n",
        "\n",
        "    # Get the test set accuracy\n",
        "    histories.append(history)\n",
        "    #Testtraingraph(history)\n",
        "  return scores, histories,n_folds,model\n",
        "\n",
        "\n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(histories):\n",
        "  for i in range(len(histories)):\n",
        "    # plot loss\n",
        "    pyplot.subplot(2, 1, 1)\n",
        "    pyplot.title('Cross Entropy Loss')\n",
        "    pyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(2, 1, 1)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
        "  pyplot.show()\n",
        "\n",
        "\n",
        "#training and validation graph per fold\n",
        "def Testtraingraph(histories):\n",
        "  # plot loss\n",
        "    pyplot.subplot(2, 1, 1)\n",
        "    pyplot.title('Cross Entropy Loss')\n",
        "    pyplot.plot(histories.history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(histories.history['val_loss'], color='orange', label='test')\n",
        "    pyplot.show()\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(2, 1, 2)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(histories.history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(histories.history['val_accuracy'], color='orange', label='test')\n",
        "    pyplot.show()\n",
        "\n",
        "# summarize model performance\n",
        "def summarize_performance(scores):\n",
        "  # print summary\n",
        "  print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
        "  # box and whisker plots of results\n",
        "  pyplot.boxplot(scores)\n",
        "  pyplot.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "M8JpaHFgocB_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading dataset\n",
        "trainX,trainY=load_dataset()\n",
        "#Normalizing./Rescaling between 0 and 1\n",
        "trainX = prep_pixels(trainX)\n",
        "#Validating our model\n",
        "scores, histories,folds,model = train_and_evaluate_model(trainX,trainY)\n",
        "# learning curves\n",
        "summarize_diagnostics(histories)\n",
        "# summarize estimated performance\n",
        "summarize_performance(scores)"
      ],
      "metadata": {
        "id": "18MBU0fJodgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validaton and train graphfinal\n",
        "Totalloss=int(len(histories[0].history['loss']))\n",
        "avg_loss=np.zeros(Totalloss)\n",
        "avg_val_loss=np.zeros(Totalloss)\n",
        "for i in range(folds):\n",
        "  avg_loss=np.add(avg_loss,histories[i].history['loss'])\n",
        "  avg_val_loss = np.add(histories[i].history['val_loss'],avg_val_loss)\n",
        "\n",
        "avg_loss=avg_loss/folds\n",
        "avg_val_loss=avg_val_loss/folds\n",
        "\n",
        "plt.plot(avg_loss[:],c='r')\n",
        "plt.plot(avg_val_loss[:],c='b')\n",
        "plt.xlabel(\"Epoches\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Training Loss\",\"Test Loss\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FrhV_mLmuhyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Give a picture and make test it if it is stroke or not stroke patient\n",
        "def Prediction(file_id):\n",
        "  # Import the necessary libraries\n",
        "  import keras.utils as image\n",
        "  from keras.models import load_model\n",
        "\n",
        "  # Download the image from Google Drive using the file ID\n",
        "\n",
        "\n",
        "  # Load the image and preprocess it for the model\n",
        "  img = image.load_img(file_id, target_size=(128, 128))\n",
        "  img_array = image.img_to_array(img)\n",
        "  img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "  # Load the pre-trained model\n",
        "  pred = model.predict(img_array)\n",
        "\n",
        "  # Get the class with the highest probability\n",
        "  class_index = np.argmax(pred)\n",
        "  # Print the accuracy of the model\n",
        "  if(pred>0.5):\n",
        "    print(\"Stroke\",\"Class Index for this picture/Stroke Patient : \" , class_index)\n",
        "  else:\n",
        "    print(\"Non-Stroke \",\"Class Index for this picture/Non-Stroke Patient : \" ,class_index)\n",
        "  return pred\n"
      ],
      "metadata": {
        "id": "_Ff0mCJfuVHE"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Give a image int the following variable File_id kindly put a link from your drive to run it\n",
        "file_id = '/content/drive/MyDrive/Project2/Test/A3.jpg'\n",
        "Prediction(file_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqqKimIDgOQq",
        "outputId": "87f026e3-a0b8-4fbf-d9ea-411b01fc6a9a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n",
            "Non-Stroke  Class Index for this picture/Non-Stroke Patient :  0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8C8XwcgDgQ4P"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}